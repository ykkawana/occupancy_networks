{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitenvvenvbd14c3dee5fc41f9bdf8f1676315d53c",
   "display_name": "Python 3.7.4 64-bit ('env': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaolin as kal\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import scipy.io\n",
    "import trimesh\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import kaolin.conversions.meshconversions as mesh_cvt\n",
    "from kaolin.transforms import pointcloudfunc as pcfunc\n",
    "from kaolin.transforms import transforms as tfs\n",
    "import sys\n",
    "sys.path.insert(0, '/home/mil/kawana/workspace/occupancy_networks')\n",
    "from im2mesh.utils import binvox_rw\n",
    "import json\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(*args):\n",
    "    return os.path.join(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_save_models(voxel_path, output_path):\n",
    "    voxel = scipy.io.loadmat(voxel_path)['voxel']\n",
    "    voxel_tensor = torch.tensor(voxel).to('cuda')\n",
    "\n",
    "    mesh_conversion = tfs.VoxelGridToTriangleMesh(threshold=0.5,\n",
    "                                                            mode='marching_cubes',\n",
    "                                                            normalize=True)\n",
    "\n",
    "    transforms = tfs.Compose([mesh_conversion,\n",
    "                                tfs.MeshLaplacianSmoothing(smoothing_iterations)])\n",
    "\n",
    "    mesh = transforms(voxel_tensor)\n",
    "\n",
    "    mesh.vertices *= side_length_scale # to adjust for occnet box size\n",
    "\n",
    "    sdf = mesh_cvt.trianglemesh_to_sdf(mesh, num_points)\n",
    "    bbox_true = torch.stack((mesh.vertices.min(dim=0)[0],\n",
    "                                mesh.vertices.max(dim=0)[0]), dim=1).view(-1)\n",
    "    points = 1.05 * (torch.rand(num_points, 3).to(mesh.vertices.device) - .5)\n",
    "    distances = sdf(points)\n",
    "    occupancies = distances <= 0\n",
    "\n",
    "    pcd_points, face_choices = mesh_cvt.trianglemesh_to_pointcloud(mesh, num_points)\n",
    "    face_normals = mesh.compute_face_normals()\n",
    "    pcd_point_normals = face_normals[face_choices]\n",
    "\n",
    "    voxel_binvox = binvox_rw.Voxels(voxel, voxel.shape, [0., 0., 0.], 1., 'xyz')\n",
    "\n",
    "\n",
    "    npv, npf = mesh.vertices.to('cpu').numpy(), mesh.faces.to('cpu').numpy()\n",
    "    np_mesh = trimesh.Trimesh(npv, npf)\n",
    "    hashd = np_mesh.md5()\n",
    "    model_output_path = join(output_path, hashd)\n",
    "    if not os.path.exists(model_output_path):\n",
    "        os.makedirs(model_output_path)\n",
    "    print(model_output_path)\n",
    "    np_mesh.export(join(model_output_path, 'model.off'))\n",
    "\n",
    "\n",
    "    binvox_rw.write(voxel_binvox, open(join(model_output_path, 'model.binvox'), 'w'))\n",
    "\n",
    "\n",
    "    packed_occupancies = np.packbits(occupancies.to('cpu').numpy())\n",
    "    np_points = points.float().to('cpu').numpy()\n",
    "    np.savez(join(model_output_path, 'points.npz'), occupancies=packed_occupancies, points=np_points, side_length_scale=side_length_scale)\n",
    "\n",
    "    np_pcd_points = pcd_points.float().to('cpu').numpy()\n",
    "    np_pcd_point_normals = pcd_point_normals.float().to('cpu').numpy()\n",
    "    np.savez(join(model_output_path, 'pointcloud.npz'), points=np_pcd_points, normals=np_pcd_point_normals, side_length_scale=side_length_scale)\n",
    "\n",
    "    np_distances = distances.float().to('cpu').numpy()\n",
    "    np.savez(join(model_output_path, 'sdf_points.npz'), points=np_pcd_points, distances=np_distances, side_length_scale=side_length_scale)\n",
    "\n",
    "    return hashd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "divide_all = 2\n",
    "divide_id = 0\n",
    "convert_model = True\n",
    "\n",
    "num_points = 100000\n",
    "smoothing_iterations = 3\n",
    "side_length_scale = 0.0107337006427915\n",
    "output_base_path = '/data/ugui0/kawana/ShapeNetLikePix3D'\n",
    "pix3d_base_path = '/data/ugui0/kawana/pix3d'\n",
    "pix3d_json_path = join(pix3d_base_path, 'pix3d.json')\n",
    "pix3d_json_path = '/home/mil/kawana/workspace/occupancy_networks/minipix3d.json'\n",
    "\n",
    "synset_to_label = {\n",
    "    '04256520': 'sofa',\n",
    "    '04379243': 'table',\n",
    "    '02691156': 'bed',\n",
    "    '02828884': 'bookcase',\n",
    "    '02933112': 'desk',\n",
    "    '02958343': 'misc',\n",
    "    '03001627': 'chair',\n",
    "    '03211117': 'tool',\n",
    "    '03636649': 'wardrobe'\n",
    "}\n",
    "\n",
    "label_to_synset = {v: k for k, v in synset_to_label.items()}\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    synset: {\n",
    "        \"id\": synset,\n",
    "        \"name\": label\n",
    "    } for synset, label in synset_to_label.items()\n",
    "}\n",
    "json.dump(metadata, open(join(output_base_path, 'metadata.yaml'), 'w'), ensure_ascii=False, indent=4, sort_keys=True, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for synset in synset_to_label:\n",
    "    class_path = join(output_base_path, synset)\n",
    "    if not os.path.exists(class_path):\n",
    "        os.makedirs(class_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "\n\n\n\n\n\n  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/data/ugui0/kawana/ShapeNetLikePix3D/02691156/ec0088362a80f66d30a681c4aa6a7766\n\n\n\n\n\n\n 33%|███▎      | 1/3 [00:03<00:07,  3.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/data/ugui0/kawana/ShapeNetLikePix3D/02691156/ec0088362a80f66d30a681c4aa6a7766\n\n\n\n\n\n\n 67%|██████▋   | 2/3 [00:07<00:03,  3.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/data/ugui0/kawana/ShapeNetLikePix3D/02691156/f74b1b3a73824f14f9aa0af8baf57547\n\n\n\n\n\n\n100%|██████████| 3/3 [00:11<00:00,  3.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
    }
   ],
   "source": [
    "pix3d_dicts = json.load(open(pix3d_json_path))\n",
    "pix3d_dicts = np.array_split(pix3d_dicts, divide_all)[divide_id].tolist()\n",
    "model_n = len(pix3d_dicts)\n",
    "\n",
    "new_pix3d_dicts = []\n",
    "\n",
    "pbar = tqdm(total=model_n)\n",
    "for model_dict in pix3d_dicts:\n",
    "    synset = label_to_synset[model_dict['category']]\n",
    "    voxel_path = join(pix3d_base_path, model_dict['voxel'])\n",
    "    output_path = join(output_base_path, synset)\n",
    "    #try:\n",
    "    modelname = convert_and_save_models(voxel_path, output_path)\n",
    "    model_dict['class_id'] = synset\n",
    "    model_dict['modelname'] = modelname\n",
    "    model_dict['class_name'] = synset_to_label[synset]\n",
    "    #except:\n",
    "    #    print('fail to convert:', voxel_path)\n",
    "\n",
    "    new_pix3d_dicts.append(model_dict)\n",
    "    pbar.update(1)\n",
    "\n",
    "df = pd.DataFrame(new_pix3d_dicts)\n",
    "pickle.dump(df, open(join('.', 'pix3d_{}_{}.pkl'.format(divide_id, divide_all)), 'wb'))"
   ]
  }
 ]
}